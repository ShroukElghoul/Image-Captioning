# Image-Captioning
## Project Overview
This project is part of Udacity Computer Vision Nanodegree. It is a neural network architecture that automatically generate captions from images.
It is a compination of a deep NN for features extraction, and a RNN for Captions generation as illustrated in the image below.

![](images/image%20captioning.PNG)

The dataset used for training is the Microsoft Common Objects in COntext (MS COCO)

## Project Structure
The project is structured as a series of Jupyter notebooks that are designed to be completed in sequential order:

0-Dataset.ipynb

1-Preliminaries.ipynb

2-Training.ipynb

3-Inference.ipynb

## Local Environment Installation

$ git clone https://github.com/ShroukElghoul/Image-Captioning.git

$ pip3 install -r requirements.txt


## Examples (images with predicted captions)


![](images/ex1.PNG)



![](images/ex2.PNG)



![](images/ex3.PNG)
